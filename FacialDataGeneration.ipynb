{"cells":[{"cell_type":"markdown","metadata":{"id":"aHN_yyrpkpEA"},"source":["# Fine-tuning with Dreambooth\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-ioxxvHoicPs"},"source":["DreamBooth is a method to personalize text2image models like stable diffusion given just a few(3~5) images of a subject. The train_dreambooth.py script shows how to implement the training procedure and adapt it for stable diffusion.\n","\n","> More information about this Dreambooth implementation:\n","https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25750,"status":"ok","timestamp":1703152875148,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"nS-daZzKZJPZ","outputId":"c3e58f2e-7d0f-4ba4-cf6c-05bbb7750027"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"wnTMyW41cC1E"},"source":["## Installing the Libraries and Requirements"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52088,"status":"ok","timestamp":1703153851618,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"5B3nyBGGb0Nt","outputId":"d70c503b-813d-45b6-9401-49ef0eaa7383"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.13.1\n","  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","Requirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.10/dist-packages (0.14.1)\n","Requirement already satisfied: torchaudio==0.13.1 in /usr/local/lib/python3.10/dist-packages (0.13.1)\n","Requirement already satisfied: torchdata==0.5.1 in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Requirement already satisfied: torchtext==0.14.1 in /usr/local/lib/python3.10/dist-packages (0.14.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.9.0)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (9.4.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1) (2.0.7)\n","Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1) (2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.1) (4.66.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.42.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2023.11.17)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xformers 0.0.23.post1 requires torch==2.1.2, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.13.1\n"]}],"source":["!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 torchtext==0.14.1"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78870,"status":"ok","timestamp":1703153930483,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"u1tYwZ30Bx4A","outputId":"9ac21caf-0d70-41dc-8df4-1098b21877d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 0.13.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\n","torchdata 0.5.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\n","torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n","!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n","%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n","%pip install -q -U --pre triton\n","%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers"]},{"cell_type":"markdown","metadata":{"id":"G0NV324ZcL9L"},"source":["## Loading the model\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1703153199543,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"kAMFC1du3NBT"},"outputs":[],"source":["model_sd = \"stabilityai/stable-diffusion-2-1\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1066,"status":"ok","timestamp":1703153200599,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"Yb9Xtey33jSC"},"outputs":[],"source":["output_dir = \"/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/stable_diffusion_weights/xyzt\"\n","!mkdir -p $output_dir"]},{"cell_type":"markdown","metadata":{"id":"qn5ILIyDJIcX"},"source":["## Training\n","\n","Three components are needed:\n","1. unique identifier\n","2. class name\n","3. images\n","\n","Instance prompt\n","a photo of [unique identifier] [class name]\n","\n","Class prompt\n","> a photo of [class name]\n","\n","The instance prompt will be as follows:\n","> a photo of zwx person\n","\n","As the subject is a person, the class prompt will be as follows:\n","> a photo of a person"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1703153200599,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"LRcAFfci6fB-"},"outputs":[],"source":["concepts_list = [\n","    {\n","        \"instance_prompt\": \"xyzt\",\n","        \"class_prompt\": \"photo of a person\",\n","        \"instance_data_dir\": \"/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/data/xyzt\",\n","        \"class_data_dir\": \"/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/data/persont\"\n","\n","    }\n","]"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1703153200600,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"h9Z5zfJx7H8d"},"outputs":[],"source":["import json\n","import os\n","import random\n","\n","for c in concepts_list:\n","  os.makedirs(c[\"instance_data_dir\"], exist_ok=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1703153200600,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"HNFSwCYQ7oQM"},"outputs":[],"source":["with open(\"concepts_list.json\", \"w\") as f:\n","  json.dump(concepts_list, f, indent=4)"]},{"cell_type":"markdown","metadata":{"id":"bgnhlQvYRteP"},"source":["### Parameters"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1703153930483,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"aUdDHMqZ8DRA","outputId":"58d28d31-1613-4df3-d7c0-9a52e30e4499"},"outputs":[{"output_type":"stream","name":"stdout","text":["13 156 1040 1e-06 104\n"]}],"source":["num_imgs = 13\n","num_class_images = num_imgs * 12\n","max_num_steps = num_imgs * 80\n","learning_rate = 1e-6 # 0.0000001\n","lr_warmup_steps = int(max_num_steps / 10)\n","print(num_imgs, num_class_images, max_num_steps, learning_rate, lr_warmup_steps)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37480,"status":"ok","timestamp":1703153967932,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"203rx5V39OyN","outputId":"146c5245-c5da-489e-dc9f-5a1a5a8cd348"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-21 10:19:06.048928: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-21 10:19:06.049015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-21 10:19:06.051086: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-21 10:19:11.008946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n","  warn(f\"Failed to load image Python extension: {e}\")\n","\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n","================================================================================\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//172.28.0.1'), PosixPath('8013')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-v100-s-3iwurjh817fv3 --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n","  warn(\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n","CUDA SETUP: Detected CUDA version 122\n","CUDA SETUP: TODO: compile library for specific version: libbitsandbytes_cuda122_nocublaslt.so\n","CUDA SETUP: Defaulting to libbitsandbytes.so...\n","CUDA SETUP: CUDA detection failed. Either CUDA driver not installed, CUDA not installed, or you have multiple conflicting CUDA libraries!\n","CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n","Traceback (most recent call last):\n","  File \"/content/train_dreambooth.py\", line 869, in <module>\n","    main(args)\n","  File \"/content/train_dreambooth.py\", line 571, in main\n","    import bitsandbytes as bnb\n","  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py\", line 6, in <module>\n","    from .autograd._functions import (\n","  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py\", line 5, in <module>\n","    import bitsandbytes.functional as F\n","  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/functional.py\", line 13, in <module>\n","    from .cextension import COMPILED_WITH_CUDA, lib\n","  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 41, in <module>\n","    lib = CUDALibrary_Singleton.get_instance().lib\n","  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 37, in get_instance\n","    cls._instance.initialize()\n","  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 27, in initialize\n","    raise Exception('CUDA SETUP: Setup Failed!')\n","Exception: CUDA SETUP: Setup Failed!\n"]}],"source":["!python3 train_dreambooth.py \\\n","  --pretrained_model_name_or_path=$model_sd \\\n","  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n","  --output_dir=$output_dir \\\n","  --revision=\"fp16\" \\\n","  --with_prior_preservation --prior_loss_weight=1.0 \\\n","  --seed=777 \\\n","  --resolution=512 \\\n","  --train_batch_size=1 \\\n","  --train_text_encoder \\\n","  --mixed_precision=\"fp16\" \\\n","  --use_8bit_adam \\\n","  --gradient_accumulation_steps=1 \\\n","  --learning_rate=$learning_rate \\\n","  --lr_scheduler=\"constant\" \\\n","  --lr_warmup_steps=80 \\\n","  --num_class_images=$num_class_images \\\n","  --sample_batch_size=4 \\\n","  --max_train_steps=$max_num_steps \\\n","  --save_interval=10000 \\\n","  --save_sample_prompt=\"xyzt\" \\\n","  --concepts_list=\"concepts_list.json\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":945,"status":"ok","timestamp":1703096351261,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"0pFau7SkLPs8","outputId":"5119a4d5-ecff-4f63-cc53-6fa5a7c906e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Weights directory:  /content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/stable_diffusion_weights/xyz/1280\n"]}],"source":["from natsort import natsorted\n","from glob import glob\n","import os\n","\n","weights_dir = natsorted(glob(output_dir + os.sep + '*'))[-1]\n","print('Weights directory: ', weights_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDfRffpwLuIf"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","def grid_img(imgs, rows, cols, scale):\n","  assert len(imgs) == rows * cols\n","\n","  w, h = imgs[0].size\n","  w, h = int(w*scale), int(h*scale)\n","\n","  grid = Image.new('RGB', size=(cols*w, rows*h))\n","  grid_w, grid_h = grid.size\n","\n","  for i, img in enumerate(imgs):\n","      img = img.resize((w,h), Image.ANTIALIAS)\n","      grid.paste(img, box=(i%cols*w, i//cols*h))\n","  return grid"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391,"output_embedded_package_id":"129IqjeBBM4fSrQCpJiPNAbJ1HbNRMtIM"},"executionInfo":{"elapsed":2605,"status":"ok","timestamp":1702495620096,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"UUv1ipRNMgnE","outputId":"5cbe5485-be70-40ed-8088-90ab193eef08"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["weights_folder = output_dir\n","#folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key = lambda x: int(x))\n","folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\" and f.isdigit()], key = lambda x: int(x))\n","\n","rows = 1\n","cols = 4\n","\n","imgs_test = []\n","\n","for imgs, folder in enumerate(folders):\n","  folder_path = os.path.join(weights_folder, folder)\n","  image_folder = os.path.join(folder_path, \"samples\")\n","  images = [f for f in os.listdir(image_folder)]\n","\n","  for i in images:\n","    img_path = os.path.join(image_folder, i)\n","    r = Image.open(img_path)\n","    imgs_test.append(r)\n","\n","if len(imgs_test) != rows * cols:\n","  raise Exception(\"The length of imgs is not equal to rows * cols.\")\n","\n","grid_img(imgs_test, rows=rows, cols=cols, scale=1)"]},{"cell_type":"markdown","metadata":{"id":"5V8wgU0HN-Kq"},"source":["## Converting the weights into (checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41318,"status":"ok","timestamp":1702495685568,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"Ugxt5Il9NQ6z","outputId":"c72e81ac-1b25-4fc1-8ad9-7aae1435fe45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reshaping encoder.mid.attn_1.q.weight for SD format\n","Reshaping encoder.mid.attn_1.k.weight for SD format\n","Reshaping encoder.mid.attn_1.v.weight for SD format\n","Reshaping encoder.mid.attn_1.proj_out.weight for SD format\n","Reshaping decoder.mid.attn_1.q.weight for SD format\n","Reshaping decoder.mid.attn_1.k.weight for SD format\n","Reshaping decoder.mid.attn_1.v.weight for SD format\n","Reshaping decoder.mid.attn_1.proj_out.weight for SD format\n","Converted to ckpt and saved in /content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/stable_diffusion_weights/xyz/1280/model.ckpt\n"]}],"source":["ckpt_path = weights_dir + \"/model.ckpt\"\n","\n","half_arg = \"--half\" # fp16\n","\n","!python convert_diffusers_to_original_stable_diffusion.py --model_path $weights_dir  --checkpoint_path $ckpt_path $half_arg\n","print(f\"Converted to ckpt and saved in {ckpt_path}\")"]},{"cell_type":"markdown","metadata":{"id":"ToNG4fd_dTbF"},"source":["## Inference (tests)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIAlvMucOVCI"},"outputs":[],"source":["import torch\n","from torch import autocast\n","from diffusers import StableDiffusionPipeline, DDIMScheduler\n","from IPython.display import display"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1703096373163,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"gQlZQNXLOj6W","outputId":"7dba0a06-a1ae-4153-92d7-33cd01f0ffdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/stable_diffusion_weights/xyz/1280\n"]}],"source":["model_path = weights_dir\n","print(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94070,"status":"ok","timestamp":1703096467218,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"OcmpaL-4Opmx","outputId":"686fb7ab-e2fe-4128-e33c-68da4b105ecf"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n","  warnings.warn(\n","You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"]}],"source":["pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wuq38BB1O7Lc"},"outputs":[],"source":["pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n","pipe.enable_xformers_memory_efficient_attention()\n","seed = 777"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"esn_wIvGziyN"},"outputs":[],"source":["#@title Saving the Model to HuggingFace\n","#@markdown If you wish your model to be avaliable for everyone, add it to the public library. If you prefer to use your model privately, add your own profile.\n","import sys\n","import torch\n","import os\n","from diffusers import StableDiffusionPipeline\n","save_concept = True #@param {type:\"boolean\"}\n","#@markdown Once you save it you can use your concept by loading the model on any `from_pretrained` function\n","name_of_your_concept = \"xyz\" #@param {type:\"string\"}\n","where_to_save_concept = \"public_library\" #@param [\"public_library\", \"privately_to_my_profile\"]\n","\n","#@markdown `hf_token_write`: leave blank if you logged in with a token with `write access` in the [Initial Setup](#scrollTo=KbzZ9xe6dWwf). If not, [go to your tokens settings and create a write access token](https://huggingface.co/settings/tokens)\n","hf_token_write = \"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\" #@param {type:\"string\"}\n","\n","if hf_token_write ==\"\":\n","  print('\u001b[1;32mYour Hugging Face write access token : ')\n","  hf_token_write=input()\n","\n","hf_token = hf_token_write\n","if(save_concept):\n","  from slugify import slugify\n","  from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n","  from huggingface_hub import create_repo\n","  from IPython.display import display_markdown\n","\n","  api = HfApi()\n","  your_username = api.whoami(token=hf_token)[\"name\"]\n","\n","\n","  if(where_to_save_concept == \"public_library\"):\n","    repo_id = f\"eliftansusunar/{slugify(name_of_your_concept)}\"\n","    #Join the Concepts Library organization if you aren't part of it already\n","    !curl -X POST -H 'Authorization: Bearer '$hf_token -H 'Content-Type: application/json' https://huggingface.co/organizations/sd-dreambooth-library/share/SSeOwppVCscfTEzFGQaqpfcjukVeNrKNHX\n","  else:\n","    repo_id = f\"{your_username}/{slugify(name_of_your_concept)}\"\n","\n","  if(not hf_token_write):\n","    with open(HfFolder.path_token, 'r') as fin: hf_token = fin.read();\n","  else:\n","    hf_token = hf_token_write\n","\n","  images_upload = os.listdir(\"/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/data/xyz\")\n","  image_string = \"\"\n","  #repo_id = f\"eliftansusunar/{slugify(name_of_your_concept)}\"\n","  for i, image in enumerate(images_upload):\n","      image_string = f'''{image_string}![image {i}](https://huggingface.co/{repo_id}/resolve/main/concept_images/{image})\n","'''\n","  readme_text = f'''---\n","license: creativeml-openrail-m\n","tags:\n","- text-to-image\n","---\n","### {name_of_your_concept} on Stable Diffusion via Dreambooth\n","#### model by {api.whoami(token=hf_token)[\"name\"]}\n","This your the Stable Diffusion model fine-tuned the {name_of_your_concept} concept taught to Stable Diffusion with Dreambooth.\n","\n","\n","You can also train your own concepts and upload them to the library by using [this notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb).\n","And you can run your new concept via `diffusers`: [Colab Notebook for Inference](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_inference.ipynb), [Spaces with the Public Concepts loaded](https://huggingface.co/spaces/sd-dreambooth-library/stable-diffusion-dreambooth-concepts)\n","\n","Here are the images used for training this concept:\n","{image_string}\n","'''\n","  #Save the readme to a file\n","  readme_file = open(\"README.md\", \"w\")\n","  readme_file.write(readme_text)\n","  readme_file.close()\n","  #Save the token identifier to a file\n","  text_file = open(\"token_identifier.txt\", \"w\")\n","  text_file.close()\n","  operations = [\n","    CommitOperationAdd(path_in_repo=\"token_identifier.txt\", path_or_fileobj=\"token_identifier.txt\"),\n","    CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n","    CommitOperationAdd(path_in_repo=\"model.ckpt\", path_or_fileobj=\"/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/stable_diffusion_weights/xyz/1280/model.ckpt\"),\n","  ]\n","  create_repo(repo_id,private=True, token=hf_token)\n","\n","  api.create_commit(\n","    repo_id=repo_id,\n","    operations=operations,\n","    commit_message=f\"Upload the concept {name_of_your_concept} embeds and token\",\n","    token=hf_token\n","  )\n","  api.upload_folder(\n","    folder_path=\"/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/stable_diffusion_weights/xyz/1280\",\n","    path_in_repo=\"\",\n","    repo_id=repo_id,\n","    token=hf_token\n","  )\n","  api.upload_folder(\n","    folder_path='/content/drive/MyDrive/Fast-Dreambooth/Sessions/DreamBooth/data/xyz',\n","    path_in_repo=\"concept_images\",\n","    repo_id=repo_id,\n","    token=hf_token\n","  )\n","display_markdown(f'''## Your concept was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})\n","''', raw=True)"]},{"cell_type":"markdown","metadata":{"id":"HsHKuCvbOQjR"},"source":["## Generating images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1UXDdUFjmWaUguZ5Pj6nECnH8Vh9KigCO"},"executionInfo":{"elapsed":20566,"status":"ok","timestamp":1703096578716,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"X1pVL0ZGPKsy","outputId":"230500d5-47f1-4d9c-c94a-a3ec9f9460f9"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["prompt = \"face portrait of xyz in the snow, realistic, hd, vivid, sunset\"\n","negative_prompt = \"bad anatomy, ugly, deformed, desfigured, distorted face, poorly drawn hands, poorly drawn face, poorly drawn feet, blurry, low quality, low definition, lowres, out of frame, out of image, cropped, cut off, signature, watermark\"\n","num_samples = 5\n","guidance_scale = 10\n","num_inference_steps = 30\n","height = 512\n","width = 512\n","\n","seed = random.randint(0, 2147483647)\n","print(\"Seed: {}\".format(str(seed)))\n","generator = torch.Generator(device='cuda').manual_seed(seed)\n","\n","with autocast(\"cuda\"), torch.inference_mode():\n","    imgs = pipe(\n","        prompt,\n","        negative_prompt=negative_prompt,\n","        height=height, width=width,\n","        num_images_per_prompt=num_samples,\n","        num_inference_steps=num_inference_steps,\n","        guidance_scale=guidance_scale,\n","        generator=generator\n","    ).images\n","\n","for img in imgs:\n","    display(img)"]},{"cell_type":"markdown","metadata":{"id":"AnLH_bHghk1N"},"source":["### Testing multiple prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10LmJUL6Tp7i1dk9cD701Ac5fH2n5JNG_"},"executionInfo":{"elapsed":19014,"status":"ok","timestamp":1703096639168,"user":{"displayName":"Elif Tansu Sunar","userId":"08405971676958221805"},"user_tz":-180},"id":"J4fQO4LkQMsC","outputId":"d1eacac4-8de1-41b8-b372-4d71d8d40b08"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["prompt = [\"photo of xyz, frontal face, Hagia Sophia in the background, natural lighting\",\n","          \"photo of xyz  in the desert, closeup, pyramids in the background, natural lighting, frontal face\",\n","          \"photo of xyz  in the forest, natural lighting, frontal face\",\n","          \"photo of xyz  as an engineer, natural lighting, frontal face, closeup, starry sky in the background\",\n","          \"face portrait of xyz in the snow, realistic, hd,vivid, sunset\"]\n","\n","negative_prompt = [\"bad anatomy, ugly, deformed, desfigured, distorted face, poorly drawn hands, poorly drawn face, poorly drawn feet, blurry, low quality, low definition, lowres, out of frame, out of image, cropped, cut off, signature, watermark\" ] * len(prompt)\n","num_samples = 1\n","guidance_scale = 10\n","num_inference_steps = 30\n","height = 512\n","width = 512\n","\n","seed = random.randint(0, 2147483647) # gera um valor aleat√≥rio\n","print(\"Seed: {}\".format(str(seed)))\n","generator = torch.Generator(device='cuda').manual_seed(seed)\n","\n","with autocast(\"cuda\"), torch.inference_mode():\n","    imgs = pipe(\n","        prompt,\n","        negative_prompt=negative_prompt,\n","        height=height, width=width,\n","        num_images_per_prompt=num_samples,\n","        num_inference_steps=num_inference_steps,\n","        guidance_scale=guidance_scale,\n","        generator=generator\n","    ).images\n","\n","for img in imgs:\n","    display(img)"]},{"cell_type":"markdown","metadata":{"id":"s0K6_4rqT4UY"},"source":["## Saving the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3PUDqJiQw9c"},"outputs":[],"source":["!mkdir results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZqrX4EwQ10U"},"outputs":[],"source":["for i, img in enumerate(imgs):\n","  img.save('results/result_{}.png'.format(i+1))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["wnTMyW41cC1E","HsHKuCvbOQjR","s0K6_4rqT4UY"],"provenance":[{"file_id":"1aoM-30yLodra-xjRtyPaOORvfbAnUxeJ","timestamp":1702474556814},{"file_id":"10v7SYx_ROnZsXjfjyh4nsgGfhHWz4R0H","timestamp":1685386770113},{"file_id":"1J5m6dimGDv_bjprwJHrS0h2Vhmz1Ef2b","timestamp":1683743703246}],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}